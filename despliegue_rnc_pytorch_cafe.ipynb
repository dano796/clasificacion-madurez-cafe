{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DESPLIEGUE DE RNC PARA PREDICCIÓN DEL TIPO DE GRANO DE CAFÉ\n",
        "\n",
        "### Integrantes\n",
        "\n",
        "- Daniel Ortiz Aristizábal\n",
        "- Felipe Torres Montoya\n",
        "- Samuel Betancur Muñoz"
      ],
      "metadata": {
        "id": "po5vsAA0VzAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyL58GtEU1n4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1) # Conv 1 de 16 kernels de tamaño 3x3\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling (128x128x16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Conv 2 de 32 kernels de tamaño 3x3\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling (64x64x32)\n",
        "\n",
        "        self.flatten = nn.Flatten() # Flatten para convertir a formato unidimensional (64x64x32 = 131.072 elementos por imagen)\n",
        "        self.dropout = nn.Dropout(p=0.2) # Dropout del 20% para evitar overfitting\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 64 * 32, 100) # Capa oculta, recibe los 131.072 elementos y genera una salida de 100 neuronas\n",
        "        self.fc2 = nn.Linear(100, num_classes)  # Capa de salida (no se usa softmax porque CrossEntropyLoss lo aplica internamente)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Establecer el dispositivo e inicializar el modelo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = CNN(in_channels=3, num_classes=5).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "V58Xi1X3yNgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b071549d-596a-41c8-ec93-fdaa9f60acb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=131072, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA90LobuxucB",
        "outputId": "2895b8d6-627c-4c52-d61b-c764d2b8b7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep = CNN(in_channels=3, num_classes=5).to(device)"
      ],
      "metadata": {
        "id": "hyD1E76CyQy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep.load_state_dict(torch.load('model_deep.pth', map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZSI6DrzyS9X",
        "outputId": "7b34eae7-d5e0-4e60-f3b0-136e51e0063e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep.eval()\n",
        "print(\"Modelo cargado exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UbK3O8CyTv5",
        "outputId": "035637a8-e566-43e7-9326-683502cce145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_deep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w62Szj72yVoS",
        "outputId": "d1552cce-fb15-46e3-85cc-d5b266ff91d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=131072, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el LabelEncoder\n",
        "filename = 'labelencoder.pkl'\n",
        "labelencoder = pickle.load(open(filename, 'rb'))\n",
        "print(\"LabelEncoder cargado exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Ij2KYNyhqe",
        "outputId": "a60af39f-7284-4343-e8a0-d746e12c249f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LabelEncoder cargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir transformaciones para preprocesamiento\n",
        "preprocess_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Tamaño que espera la red\n",
        "    transforms.ToTensor(), # Convierte imagen de [0,255] a [0,1]\n",
        "])\n",
        "\n",
        "# Función para preprocesar una imagen\n",
        "def preprocess_image(imagen):\n",
        "    imagen = preprocess_transforms(imagen)\n",
        "    imagen = imagen.unsqueeze(0)\n",
        "    return imagen"
      ],
      "metadata": {
        "id": "seFPiDgPzDUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura de la carpeta con las imágenes\n",
        "path = \"futuro\"\n",
        "files = os.listdir(path)\n",
        "\n",
        "futuro = []\n",
        "image_names = []\n",
        "\n",
        "for f in files:\n",
        "    if f.endswith(\".jpg\"):\n",
        "        imagen = Image.open(os.path.join(path, f)).convert('RGB')\n",
        "        print(f)\n",
        "        imagen_tensor = preprocess_image(imagen)\n",
        "        futuro.append(imagen_tensor)\n",
        "        image_names.append(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X717z_pIzGcF",
        "outputId": "0eb5789d-f74a-45b0-bb08-74dfaa2c4b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pinton1.jpg\n",
            "pinton4.jpg\n",
            "seco2.jpg\n",
            "seco1.jpg\n",
            "maduro3.jpg\n",
            "maduro6.jpg\n",
            "maduro4.jpg\n",
            "sobremaduro1.jpg\n",
            "sobremaduro4.jpg\n",
            "maduro1.jpg\n",
            "seco3.jpg\n",
            "maduro5.jpg\n",
            "maduro2.jpg\n",
            "pinton6.jpg\n",
            "verde2.jpg\n",
            "verde1.jpg\n",
            "sobremaduro2.jpg\n",
            "sobremaduro3.jpg\n",
            "seco4.jpg\n",
            "seco5.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la lista de imágenes en un tensor\n",
        "img_futuro = torch.cat(futuro, dim=0).to(device)"
      ],
      "metadata": {
        "id": "HW31Rd8xyy2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la predicción\n",
        "with torch.no_grad():\n",
        "    predicciones = model_deep(img_futuro)\n",
        "    _, etiquetas_predichas = torch.max(predicciones, dim=1)\n",
        "    etiquetas_predichas = etiquetas_predichas.cpu().numpy()"
      ],
      "metadata": {
        "id": "kjAjgrIizJkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificar las etiquetas\n",
        "etiquetas_decodificadas = labelencoder.inverse_transform(etiquetas_predichas)"
      ],
      "metadata": {
        "id": "70tQD5-PzRrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir resultados\n",
        "print(\"\\nPredicciones:\")\n",
        "for nombre, etiqueta in zip(image_names, etiquetas_decodificadas):\n",
        "    print(f\"Imagen: {nombre} -> Clase predicha: {etiqueta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HztFVm4AzTef",
        "outputId": "eb55978f-0511-405d-d3c6-5fef64a5ce43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicciones:\n",
            "Imagen: pinton1.jpg -> Clase predicha: pintones\n",
            "Imagen: pinton4.jpg -> Clase predicha: maduros\n",
            "Imagen: seco2.jpg -> Clase predicha: secos\n",
            "Imagen: seco1.jpg -> Clase predicha: secos\n",
            "Imagen: maduro3.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro6.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro4.jpg -> Clase predicha: maduros\n",
            "Imagen: sobremaduro1.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: sobremaduro4.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro1.jpg -> Clase predicha: maduros\n",
            "Imagen: seco3.jpg -> Clase predicha: secos\n",
            "Imagen: maduro5.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro2.jpg -> Clase predicha: maduros\n",
            "Imagen: pinton6.jpg -> Clase predicha: maduros\n",
            "Imagen: verde2.jpg -> Clase predicha: verdes\n",
            "Imagen: verde1.jpg -> Clase predicha: verdes\n",
            "Imagen: sobremaduro2.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: sobremaduro3.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: seco4.jpg -> Clase predicha: secos\n",
            "Imagen: seco5.jpg -> Clase predicha: secos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Despliegue Optimizado\n"
      ],
      "metadata": {
        "id": "BvjN0jzmKatM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Optimized(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN_Optimized, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1) # Conv 1 de 16 kernels de tamaño 3x3\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling (128x128x16)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Conv 2 de 32 kernels de tamaño 3x3\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling (64x64x32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 48, kernel_size=3, padding=1) # Conv 3 de 48 kernels de tamaño 3x3\n",
        "        self.bn3 = nn.BatchNorm2d(48)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling (32x32x48)\n",
        "\n",
        "        self.flatten = nn.Flatten() # Flatten para convertir a formato unidimensional (32x32x48 = 49.152 elementos por imagen)\n",
        "        self.dropout = nn.Dropout(p=0.2) # Dropout del 20% para evitar overfitting\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 32 * 48, 70) # Capa oculta 1, recibe los 49.152 elementos y genera una salida de 70 neuronas\n",
        "        self.fc2 = nn.Linear(70, 35) # Capa Oculta 2 con 35 neuronas\n",
        "        self.fc3 = nn.Linear(35, num_classes)  # Capa de salida (no se usa softmax porque CrossEntropyLoss lo aplica internamente)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Establecer el dispositivo e inicializar el modelo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_opt = CNN_Optimized(in_channels=3, num_classes=5).to(device)\n",
        "print(model_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HihJs-1FKISv",
        "outputId": "00c31752-0540-4d5d-9f72-0c8ab072ce4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Optimized(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=49152, out_features=70, bias=True)\n",
            "  (fc2): Linear(in_features=70, out_features=35, bias=True)\n",
            "  (fc3): Linear(in_features=35, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep_opt = CNN_Optimized(in_channels=3, num_classes=5).to(device)"
      ],
      "metadata": {
        "id": "8GVIRMpaKc-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep_opt.load_state_dict(torch.load('model_deep_opt.pth', map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yyqBP6KKfjn",
        "outputId": "eb3df876-64cc-4d54-8d3d-e7521579ad33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep_opt.eval()\n",
        "print(\"Modelo cargado exitosamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqTQz_-bKhBX",
        "outputId": "9eef5bbd-be81-4415-9850-2f1947682598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_deep_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNW7aT3mKjEO",
        "outputId": "47f9619a-ebbd-434f-a562-9f20bd98337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Optimized(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=49152, out_features=70, bias=True)\n",
            "  (fc2): Linear(in_features=70, out_features=35, bias=True)\n",
            "  (fc3): Linear(in_features=35, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la predicción\n",
        "with torch.no_grad():\n",
        "    predicciones = model_deep_opt(img_futuro)\n",
        "    _, etiquetas_predichas = torch.max(predicciones, dim=1)\n",
        "    etiquetas_predichas = etiquetas_predichas.cpu().numpy()"
      ],
      "metadata": {
        "id": "7l_pk9uWKqMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodificar las etiquetas\n",
        "etiquetas_decodificadas = labelencoder.inverse_transform(etiquetas_predichas)"
      ],
      "metadata": {
        "id": "-8kBdATtKsCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir resultados\n",
        "print(\"\\nPredicciones:\")\n",
        "for nombre, etiqueta in zip(image_names, etiquetas_decodificadas):\n",
        "    print(f\"Imagen: {nombre} -> Clase predicha: {etiqueta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA5bh6TFKs_l",
        "outputId": "285b6536-3243-4292-b62e-958f14720c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicciones:\n",
            "Imagen: pinton1.jpg -> Clase predicha: pintones\n",
            "Imagen: pinton4.jpg -> Clase predicha: pintones\n",
            "Imagen: seco2.jpg -> Clase predicha: secos\n",
            "Imagen: seco1.jpg -> Clase predicha: secos\n",
            "Imagen: maduro3.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro6.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro4.jpg -> Clase predicha: maduros\n",
            "Imagen: sobremaduro1.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: sobremaduro4.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: maduro1.jpg -> Clase predicha: maduros\n",
            "Imagen: seco3.jpg -> Clase predicha: secos\n",
            "Imagen: maduro5.jpg -> Clase predicha: maduros\n",
            "Imagen: maduro2.jpg -> Clase predicha: maduros\n",
            "Imagen: pinton6.jpg -> Clase predicha: pintones\n",
            "Imagen: verde2.jpg -> Clase predicha: verdes\n",
            "Imagen: verde1.jpg -> Clase predicha: verdes\n",
            "Imagen: sobremaduro2.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: sobremaduro3.jpg -> Clase predicha: sobremaduros\n",
            "Imagen: seco4.jpg -> Clase predicha: secos\n",
            "Imagen: seco5.jpg -> Clase predicha: secos\n"
          ]
        }
      ]
    }
  ]
}